# -*- coding: utf-8 -*-
"""PS1-Practice

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cqK7Ht6j73hVC7LURoaJBKqlFJwH-kgi

DEALING WITH THE IMBALANCED DATA (CORRECT AND FINAL)
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# %%bash
# pip install imbalanced-learn

import pandas as pd
df=pd.read_csv('/content/DATASHEET - FEATURES.csv')
df.head()

df.shape

df['species'].value_counts()

import seaborn as sns
sns.countplot(x='species', data=df)

from matplotlib import pyplot as plt

for column in df:
  sns.displot(x=column, data=df)
  plt.savefig('Column plots')

"""TO SEE THE ACCURACY WITH THE IMBALANCED DATA REFER ML BY SIDDHARDHAN heart disease predicition video"""

X=df.drop(['species', 'file(after noise cancellation)'], axis = 1)  #taken from ML BY SIDDHARDHAN heart disease predicition video and not krish naik
y = df['species']
#X = df.drop(columns='file(after noise cancellation)',axis=1)
print(X)

"""1)Cross Validation Like KFOLD and Hyperpaqrameter Tuning"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
from sklearn.model_selection import KFold
import numpy as np
from sklearn.model_selection import GridSearchCV

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

log_class=LogisticRegression()
grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}
cv=KFold(n_splits=5,random_state=0,shuffle=True)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7)

clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1,scoring='f1_macro')
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

"""GOING BACK TO THE TRAIN AND TEST DATA"""

y_train.value_counts()

class_weight=dict({0:1,1:3})    #this rsatio will give 1 ,2.4 times more weightage than 0..(THE RATIO WILL KEEP CHANGING DEPENDING ON YOOR VALUES OF Y_TRAIN OR Y_TEST FROM ABOVE)

"""FINDING CV AND ACCURACIES FOR DIFFERNT ALGORTIHMS"""

models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier()]

def compare_models_train_test():

  for model in models:

    # training the model
    model.fit(X_train, y_train)

    # evaluating the model
    test_data_prediction = model.predict(X_test)

    accuracy = accuracy_score(y_test, test_data_prediction)

    print('Accuracy score of the ', model, ' = ', accuracy)

compare_models_train_test()

"""COMPARING CV SCORE AGAIN"""

def compare_models_cross_validation():

  for model in models:

    cv_score = cross_val_score(model, X,y, cv=10)  #cv represents the number of splits

    mean_accuracy = sum(cv_score)/len(cv_score)

    mean_accuracy = mean_accuracy*100

    mean_accuracy = round(mean_accuracy, 2)

    print('Cross Validation accuracies for ', model, '=  ', cv_score)
    print('Accuracy % of the ', model, mean_accuracy)
    print('----------------------------------------------')

compare_models_cross_validation()

from sklearn.ensemble import RandomForestClassifier
classifier=RandomForestClassifier(class_weight=class_weight)
classifier.fit(X_train,y_train)

y_pred=classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
#print(accuracy_score(y_train,y_pred))

print(classification_report(y_test,y_pred))

"""from ML SID."""

scaler = StandardScaler()

scaler.fit(X)

standardized_data = scaler.transform(X)

input_data = (5,0.84,0.5589,50)

# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardize the input data
std_data = scaler.transform(input_data_reshaped)
#print(std_data)

prediction = classifier.predict(std_data)
print(prediction)

if (prediction[0] == 0):
  print('The species 0 found')
else:
  print('The species 1 found')

"""CHKING ALL PARAMETERS"""